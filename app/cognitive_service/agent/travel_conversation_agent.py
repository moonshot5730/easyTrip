import textwrap
from pprint import pprint

from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import PromptTemplate
from langgraph.constants import END
from langgraph.graph import StateGraph
from langgraph.prebuilt import ToolNode

from app.cognitive_service.agent_core.graph_state import AgentState
from app.cognitive_service.agent_parser.llm_json_parser import extract_info_llm_parser
from app.cognitive_service.agent_tool.extract_json_tool import extract_travel_info
from app.cognitive_service.agent_tool.travel_search_tool import search_place_tool
from app.external.openai.openai_client import precise_llm_nano, creative_llm_nano
from shared.datetime_util import get_kst_timestamp_label, get_kst_year_month_date_label


def travel_conversation(state: AgentState):
    user_query = state["messages"][-1].content if state["messages"] else ""

    travel_conversation_prompt = PromptTemplate.from_template(textwrap.dedent("""
    ë„ˆëŠ” {user_name}ê³¼ì˜ ëŒ€í™”ë¥¼ í†µí•´ ì—¬í–‰ ìŠ¤íƒ€ì¼, ì¼ì •, ì¥ì†Œë¥¼ ë¶„ì„í•´ì£¼ëŠ” ëŒ€í•œë¯¼êµ­ ì—¬í–‰ ì»¨ì„¤í„´íŠ¸ KETì•¼.
    KETëŠ” ëŒ€í•œë¯¼êµ­ì˜ ë‹¤ì–‘í•œ ì§€ì—­ê³¼ ë„ì‹œë¥¼ ì†Œê°œí•´.
    KETëŠ” êµ­ë‚´ ì—¬í–‰ ê³„íšì„ ì„¸ìš¸ ì¤€ë¹„ë¥¼ í•˜ëŠ” {user_name}ê³¼ ëŒ€í™”í•˜ë©´ì„œ ì—¬í–‰ ê³„íšì— í•„ìš”í•œ ì •ë³´ë¥¼ ë¶„ì„ ì •ë¦¬í•´.
    ì˜¤ëŠ˜ì˜ ë‚ ì§œëŠ” {today}ì•¼. 
    
    ì‚¬ìš©ì {user_name}ì˜ ì—¬í–‰ ì •ë³´:
    - travel_place (ì—¬í–‰ ì¥ì†Œ): {travel_place} 
    - travel_schedule (ì—¬í–‰ ì¼ì •): {travel_schedule}
    - travel_style (ì—¬í–‰ ìŠ¤íƒ€ì¼): {travel_style}
    - need_place_search (ì—¬í–‰ ì¥ì†Œ ê²€ìƒ‰ ìš”ì²­): {need_place_search}
    ** ë¯¸ì •ì¸ ê²½ìš° ëŒ€í™”ë¡œ ìì—½ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë´…ë‹ˆë‹¤.
    
    KETì˜ ëª©ì :
    {user_name}ì˜ ì—¬í–‰ ì •ë³´ë¥¼ ìœ„í•´ ì¼ì •, ìŠ¤íƒ€ì¼, ì¥ì†Œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë³´ê³ , í•„ìš”í•˜ë‹¤ëŠ” ìš”ì²­ì„ í•©ë‹ˆë‹¤.
    KETëŠ” ì‚¬ìš©ìì˜ ì´ë¦„ì„ ìì£¼ ì–¸ê¸‰í•˜ë©´ì„œ ì¹œì ˆí•˜ê²Œ ì ‘ê·¼í•©ë‹ˆë‹¤.
    
    KETëŠ” {user_name}ì„ ìœ„í•œ ì—¬í–‰ ì •ë³´ë¥¼ ìœ„í•œ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤:
    ì—¬í–‰ ê³„íšì„ ìœ„í•´ {user_name}ì˜ ì—¬í–‰ ì •ë³´ë“¤ì„ ì¹œì ˆí•˜ê²Œ ë¬¼ì–´ë³´ê³  ìœ ë„í•©ë‹ˆë‹¤.
    - ì—¬í–‰ ìŠ¤íƒ€ì¼ : ì–´ë–¤ ì—¬í–‰ ìŠ¤íƒ€ì¼ì„ ì›í•˜ì‹œë‚˜ìš”? ë¬¸í™”, ìì—°, íœ´ì‹, íë§, ìŒì‹ ë“±ë“±
    - ì—¬í–‰ ì¥ì†Œ : ì–´ë–¤ ì§€ì—­ì„ ì—¬í–‰í•˜ê³  ì‹¶ì€ê°€ìš”?, ê³„íší•œ ì¥ì†Œê°€ ìˆì„ê¹Œìš”?
    - ì—¬í–‰ ì¼ì • : ê³„íší•œ ì—¬í–‰ ì¼ì •ì´ ìˆì„ê¹Œìš”?
    ** í•„ìš”í•œ ê²½ìš° ì—¬í–‰ ì¥ì†Œë¥¼ ìœ„í•œ ì›¹ ê²€ìƒ‰ì„ ì§€ì›í•´ì¤„ ìˆ˜ ìˆë‹¤ê³  ì•ˆë‚´í•©ë‹ˆë‹¤.

    
    ì‚¬ìš©ì ë©”ì‹œì§€: {user_query}""")).partial(user_name="ë¬¸í˜„ì¤€", today=get_kst_year_month_date_label())

    formatted_prompt = travel_conversation_prompt.format(
        travel_place=state.get("travel_place", "ë¯¸ì •"),
        travel_schedule=state.get("travel_schedule", "ë¯¸ì •"),
        travel_style=state.get("travel_place", "ë¯¸ì •"),
        need_place_search=state.get("need_place_search", "false"),
        user_query=user_query,
    )

    llm_response = creative_llm_nano.invoke(formatted_prompt)
    print(f"ğŸ§¾ ì „ì†¡í•œ í”„ë¡¬í”„íŠ¸ ì •ë³´: {formatted_prompt}\nì›ë³¸ LLM ì‘ë‹µ:\n {llm_response.content}")
    return {
        "messages": [AIMessage(content=llm_response.content)],
        "travel_conversation_raw_output": llm_response
    }


def should_conversation(state: AgentState) -> str:
    extract_travel_info = all([
        state.get("travel_schedule") not in [None, "", "ë¯¸ì •"],
        state.get("travel_style") not in [None, "", "ë¯¸ì •"]
    ])

    if extract_travel_info:
        if state.get("travel_place") not in [None, "", "ë¯¸ì •"]:
            return "complete"
        elif state.get("need_place_search") is True:
            return "search"
        else:
            return "loop"

    return "complete"


def create_graph():
    graph = StateGraph(AgentState)

    # ë…¸ë“œ ë“±ë¡
    graph.add_node("travel_conversation", travel_conversation)
    graph.add_node("extract_info_llm_parser", extract_info_llm_parser)
    graph.add_node("extract_info_tool", ToolNode(tools=[extract_travel_info]))
    graph.add_node("search_place_tool", ToolNode(tools=[search_place_tool]))

    # ì‹œì‘ ì§€ì 
    graph.set_entry_point("travel_conversation")

    # travel_conversation â†’ ToolNode
    graph.add_edge("travel_conversation", "extract_info_llm_parser")

    # ToolNode â†’ travel_conversation (ì¡°ê±´ì  ë°˜ë³µ)
    graph.add_conditional_edges(
        "extract_info_llm_parser",
        path=should_conversation,
        path_map={
            "loop": "travel_conversation",
            "search": "search_place_tool",  # ì˜ˆì‹œë¡œ ì¥ì†Œ ê²€ìƒ‰ ToolNode
            "complete": END
        }
    )

    graph.add_conditional_edges(  # ğŸ” ê²€ìƒ‰ ë…¸ë“œë„ ì¢…ë£Œë˜ë„ë¡ ë¶„ê¸° ì¶”ê°€
        "search_place_tool",
        path=lambda state: END,
        path_map={END: END}
    )

    return graph.compile()


travel_conversation_graph = create_graph()
print(travel_conversation_graph.get_graph().draw_mermaid())


start_message = {
    "messages": [
        HumanMessage(content="ì—¬í–‰ì„ ê°€ê³  ì‹¶ì€ë° ì–´ë””ê°€ ì¢‹ì„ê¹Œìš”?")
    ]
}

result = travel_conversation_graph.invoke(start_message)
pprint(result)



