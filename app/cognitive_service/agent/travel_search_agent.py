import textwrap

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.prompts import PromptTemplate

from app.cognitive_service.agent_core.graph_state import (AgentState,
                                                          get_last_message)
from app.cognitive_service.agent_llm.llm_models import (creative_llm_nano,
                                                        precise_llm_mini,
                                                        precise_llm_nano)
from app.cognitive_service.agent_tool.travel_search_tool import (
    parse_tavily_results, place_search_tool)
from app.core.logger.logger_config import api_logger
from shared.datetime_util import get_kst_year_month_date_label

travel_search_system_prompt_template = textwrap.dedent(
    """
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì—¬í–‰ ì§€ì—­ê³¼ ì¥ì†Œë“¤ì„ ê²€ìƒ‰í•´ì£¼ëŠ” AI ë¦¬ì„œì¹˜ KETì…ë‹ˆë‹¤.
    
    KETì˜ ë„êµ¬ ì‚¬ìš© ê·œì¹™:
    - ì‚¬ìš©ì ì§ˆë¬¸ì´ ì›¹ ê²€ìƒ‰ í˜¹ì€ ê²€ìƒ‰ì„ ìš”ì²­í•œ ê²½ìš° ì›¹ ê²€ìƒ‰ ë„êµ¬ 'tavily_web_search'ì„ ì‚¬ìš©í•˜ì„¸ìš”.
      ê²€ìƒ‰ ì§ˆë¬¸ í‚¤ì›Œë“œ: ê²€ìƒ‰, ì›¹ì„œí•‘, ì„œì¹­, ì¸í„°ë„· ê²€ìƒ‰, ë¸”ë¡œê¹…
    - ì‚¬ìš©ìê°€ ë‹¨ìˆœí•˜ê²Œ ì—¬í–‰ ì§€ì—­ ë° ì¥ì†Œë¥¼ ì¶”ì²œ í˜¹ì€ ì œì•ˆí•œ ê²½ìš° ì—¬í–‰ ì§€ì—­ê³¼ ì¥ì†Œë¥¼ ì œì•ˆí•˜ì„¸ìš”.
      ì œì•ˆ ë° ì¶”ì²œ í‚¤ì›Œë“œ: ì œì•ˆí•´ì¤˜, ì¶”ì²œí•´ì¤˜, ì•Œë ¤ì¤˜
    
    ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
    - tavily_web_search: ì‚¬ìš©ì ì§ˆì˜ì—ì„œ ì ì ˆí•œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì •ë¦¬í•´ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ì‚¬ìš©ì ì§ˆë¬¸: {user_query}
    """
)


def travel_search_conversation(state: AgentState):
    api_logger.info(
        f"[travel_search_conversation!!!] í˜„ì¬ ìƒíƒœ ì •ë³´ì…ë‹ˆë‹¤: {state.get("messages", [])}"
    )

    user_query = state.get("user_query") or get_last_message(
        messages=state.get("messages", [])
    )
    new_user_message = HumanMessage(content=user_query)

    system_message = SystemMessage(
        content=PromptTemplate.from_template(
            travel_search_system_prompt_template
        ).format(user_query=user_query)
    )
    messages = [system_message] + [new_user_message]

    llm_response = precise_llm_nano.bind_tools([place_search_tool]).invoke(messages)

    tool_calls = getattr(llm_response, "tool_calls", None)
    tool_messages = []
    results = []

    if tool_calls:
        for tool_call in tool_calls:
            if tool_call["name"] == "tavily_web_search":
                args = tool_call["args"]
                tool_result = place_search_tool.invoke(args)
                results.append(tool_result)

                tool_content = parse_tavily_results(tool_result)
                tool_messages.append(AIMessage(content=tool_content))

    return {
        "messages": state.get("messages", [])
        + [new_user_message, AIMessage(content=llm_response.content)]
        + tool_messages
    }


if __name__ == "__main__":
    messages = [
        SystemMessage(content=travel_search_system_prompt_template),
        HumanMessage(content="ëŒ€í•œë¯¼êµ­ ê°•ì›ë„ ì—¬í–‰ì§€ì— ëŒ€í•´ì„œ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."),
    ]

    binding_llm = precise_llm_nano.bind_tools([place_search_tool])
    llm_response = binding_llm.invoke(messages)

    # ğŸ“Œ function callì´ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸
    tool_calls = getattr(llm_response, "tool_calls", None)

    results = []
    if tool_calls:
        for tool_call in tool_calls:
            if tool_call["name"] == "tavily_web_search":
                args = tool_call["args"]
                tool_result = place_search_tool.invoke(args)
                results.append(tool_result)

    print(f"llm ì‘ë‹µ {llm_response}")
    print(f"tool_calls ì •ë³´: {tool_calls}")
    print(f"ê²€ìƒ‰ ê²°ê³¼ : {results}")
