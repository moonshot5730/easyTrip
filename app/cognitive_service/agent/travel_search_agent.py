import textwrap

from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import PromptTemplate

from app.cognitive_service.agent_core.graph_state import AgentState, get_last_message
from app.cognitive_service.agent_llm.llm_models import creative_llm_nano, precise_llm_mini, precise_llm_nano
from app.cognitive_service.agent_tool.travel_search_tool import place_search_tool
from app.core.logger.logger_config import api_logger
from shared.datetime_util import get_kst_year_month_date_label


travel_search_system_prompt_template = textwrap.dedent("""
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì—¬í–‰ ì¥ì†Œ ë° ë„ì‹œë¥¼ ê²€ìƒ‰í•´ì£¼ëŠ” AI ë¦¬ì„œì¹˜ KETì…ë‹ˆë‹¤.
    
    KETì˜ ë„êµ¬ ì‚¬ìš© ê·œì¹™:
    - ì‚¬ìš©ì ì§ˆë¬¸ì´ ì›¹ ê²€ìƒ‰ í˜¹ì€ ê²€ìƒ‰ì„ ìš”êµ¬í•œ ê²½ìš° ì›¹ ê²€ìƒ‰ ë„êµ¬ 'tavily_web_search'ì„ ì‚¬ìš©í•˜ì„¸ìš”.
    - ì‚¬ìš©ìê°€ ë‹¨ìˆœí•˜ê²Œ ì—¬í–‰ ì§€ì—­ ë° ì¥ì†Œë¥¼ ì¶”ì²œ í˜¹ì€ ì œì•ˆí•œ ê²½ìš° ì—¬í–‰ ì§€ì—­ê³¼ ì¥ì†Œë¥¼ ì œì•ˆí•˜ì„¸ìš”.
    
    ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
    - tavily_web_search: ëŒ€í•œë¯¼êµ­ ì—¬í–‰ì§€ë¥¼ ì£¼ì œë¡œ ê²€ìƒ‰ì–´ë¥¼ ì „ë‹¬í•´ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ì‚¬ìš©ì ì§ˆë¬¸: {user_query}
    """)


def travel_search_conversation(state: AgentState):
    api_logger.info(f"[travel_search_conversation!!!] í˜„ì¬ ìƒíƒœ ì •ë³´ì…ë‹ˆë‹¤: {state.get("messages", [])}")

    user_query = state.get("user_query") or get_last_message(messages=state.get("messages", []))
    new_user_message = HumanMessage(content=user_query)

    system_message = SystemMessage(content=PromptTemplate.from_template(travel_search_system_prompt_template).format(user_query=user_query))
    messages = [system_message] + [new_user_message]

    api_logger.info(f"[travel_search_conversation] messages : {messages}")

    llm_response = precise_llm_nano.bind_tools([place_search_tool]).invoke(messages)
    api_logger.info(f"[travel_search_conversation] ì‘ë‹µ : {llm_response.content}")

    tool_calls = getattr(llm_response, "tool_calls", None)

    results = []
    if tool_calls:
        for tool_call in tool_calls:
            if tool_call["name"] == "tavily_web_search":
                args = tool_call["args"]
                tool_result = place_search_tool.invoke(args)
                results.append(tool_result)

        api_logger.info(f"[ì›¹ ê²€ìƒ‰ ê²°ê³¼!! ] {results}")

    return {
        "messages": state.get("messages", []) + [new_user_message, AIMessage(content=llm_response.content)]
    }


if __name__ == '__main__':
    messages = [
        SystemMessage(content=travel_search_system_prompt_template),
        HumanMessage(content="ëŒ€í•œë¯¼êµ­ ê°•ì›ë„ ì—¬í–‰ì§€ì— ëŒ€í•´ì„œ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.")
    ]

    binding_llm = precise_llm_nano.bind_tools([place_search_tool])
    llm_response = binding_llm.invoke(messages)

    # ğŸ“Œ function callì´ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸
    tool_calls = getattr(llm_response, "tool_calls", None)

    results = []
    if tool_calls:
        for tool_call in tool_calls:
            if tool_call["name"] == "tavily_web_search":
                args = tool_call["args"]
                tool_result = place_search_tool.invoke(args)
                results.append(tool_result)

    print(f"llm ì‘ë‹µ {llm_response}")
    print(f"tool_calls ì •ë³´: {tool_calls}")
    print(f"ê²€ìƒ‰ ê²°ê³¼ : {results}")