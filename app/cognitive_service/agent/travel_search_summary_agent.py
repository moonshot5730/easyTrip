import textwrap

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.prompts import PromptTemplate

from app.cognitive_service.agent_core.graph_state import AgentState
from app.cognitive_service.agent_llm.llm_models import precise_llm_nano
from app.cognitive_service.agent_tool.travel_search_tool import \
    place_search_tool
from app.core.logger.logger_config import api_logger
from app.external.openai.openai_client import precise_openai_fallbacks
from shared.datetime_util import get_kst_year_month_date_label

travel_search_summary_system_prompt_template = textwrap.dedent(
    """
    ë‹¹ì‹ ì€ ì›¹ìœ¼ë¡œ ê²€ìƒ‰ëœ ì •ë³´ë“¤ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ìš”ì•½ ì •ë¦¬í•´ì£¼ëŠ” ê¸€ì“°ê¸° ì „ë¬¸ê°€ KETì…ë‹ˆë‹¤.
    KETëŠ” ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì •ë¦¬ëœ ì—¬í–‰ ê´€ë ¨ ê²°ê³¼ ì •ë³´ë“¤ì„ ì „ë‹¬ë°›ìŠµë‹ˆë‹¤.
    ê²€ìƒ‰í•œ ë‚ ì§œëŠ” {today}ì…ë‹ˆë‹¤. 
    
    KETì˜ ì‘ë‹µ ìŠ¤íƒ€ì¼:
    - ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ì •ë¦¬í–ˆë‹¤ê³  ì•ˆë‚´í•©ë‹ˆë‹¤.
    - ì •ë³´ê°€ ë„ˆë¬´ ë§ì€ ê²½ìš° ë°˜ë³µë˜ê³ , ê°•ì¡°ë˜ëŠ” ì •ë³´ 3~5ê°œë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
    - URL ë§í¬ ì •ë³´ë¥¼ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í‘œì‹œí•´ì¤ë‹ˆë‹¤.
    ** ë³„ë„ë¡œ ì°¸ì¡°í•œ ë§í¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    
    ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì •ë³´ : {search_results}
    """
)


def travel_search_summary_conversation(state: AgentState):
    """
    ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ ìš”ì•½ ì‘ë‹µì„ ë‚´ë ¤ì¤ë‹ˆë‹¤.
    :param state: ê·¸ë˜í”„ ìŠ¤í…Œì´íŠ¸ ì •ë³´
    :return: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì„œ ë‚´ë ¤ì¤ë‹ˆë‹¤. [ì´ë²¤íŠ¸ì—ì„œ ì²˜ë¦¬]
    """
    api_logger.info(
        f"[travel_search_summary_conversation!!!] í˜„ì¬ ìƒíƒœ ì •ë³´ì…ë‹ˆë‹¤: {state.get("messages", [])}"
    )

    system_message = SystemMessage(
        content=PromptTemplate.from_template(
            travel_search_summary_system_prompt_template
        ).format(
            search_results=state.get("websearch_results", []),
            today=get_kst_year_month_date_label(),
        )
    )
    llm_response = precise_openai_fallbacks.invoke([system_message])

    return {
        "messages": state.get("messages", [])
        + [AIMessage(content=llm_response.content)],
        "is_websearh": False,
    }


if __name__ == "__main__":
    messages = [
        SystemMessage(content=travel_search_summary_system_prompt_template),
        HumanMessage(content="ëŒ€í•œë¯¼êµ­ ê°•ì›ë„ ì—¬í–‰ì§€ì— ëŒ€í•´ì„œ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."),
    ]

    binding_llm = precise_openai_fallbacks.bind_tools([place_search_tool])
    llm_response = binding_llm.invoke(messages)

    # ğŸ“Œ function callì´ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸
    tool_calls = getattr(llm_response, "tool_calls", None)

    results = []
    if tool_calls:
        for tool_call in tool_calls:
            if tool_call["name"] == "tavily_web_search":
                args = tool_call["args"]
                tool_result = place_search_tool.invoke(args)
                results.append(tool_result)

    print(f"llm ì‘ë‹µ {llm_response}")
    print(f"tool_calls ì •ë³´: {tool_calls}")
    print(f"ê²€ìƒ‰ ê²°ê³¼ : {results}")
